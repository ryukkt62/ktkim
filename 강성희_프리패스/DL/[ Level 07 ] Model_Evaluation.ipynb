{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IL6dIhEak3HO"
   },
   "source": [
    "# 딥러닝 온라인 심화반 <Level 7>에 오신 것을 환영합니다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R89aOZHjk3HS"
   },
   "source": [
    "지금까지 퍼셉트론, 다층 퍼셉트론 등 많은 알고리즘을 다뤘지만, 현업에서, 그리고 실제 연구에서 이 알고리즘을 사용하기 위해서는 알고리즘의 성능을 정량적으로 측정하고 그 성능을 분석하는게 중요합니다. 이번 시간에는 구현한 딥러닝 모델의 성능을 평가하는 다양한 방법에 대해 살펴볼 것입니다. 마지막 과제로는 우편번호 손글씨 이미지(MNIST)로 학습한 다층 퍼셉트론의 성능을 평가하고, 이 모델을 활용하여 데이터 사이언스 경진대회 [캐글(Kaggle)](https://kaggle.com)에 도전하는 시간을 가져볼 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vgQVsAt8k3HU"
   },
   "source": [
    "## Overfitting(과대적합)과 Underfitting(과소적합)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "선형 회귀 분석과 같은 통계적 모델을 사용할 때, 새로운 데이터에 대해 예측하기 위한 훈련 세트에 모형을 적합시킵니다. 이때 Overfitting과 Underfitting의 두 가지 문제가 발생할 수 있습니다. Overfitting과 Underfitting이 무엇인지 알아봅시다.\n",
    "\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=1f9BP-G9nW2yaaCvb4eAtXWdmNOCw0607\" width=\"800\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lL-JyvFwk3HW"
   },
   "source": [
    "### Overfitting(과대적합)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wx2uiDHTk3HX"
   },
   "source": [
    "Overfitting은 모델이 Training Data에 너무 잘 맞아서 일반성이 떨어지게 되는 문제입니다. 즉 Training Data를 너무 과하게 학습해 학습되지 않은 데이터가 들어오면 분류하지 못하게 되는 문제를 일으킵니다. 위의 오른쪽 그림에서 볼 수 있듯이 Training Data를 거의 다 거치거나 분류해내며 굉장히 높은 성능을 보여주고 있지만, 새로운 변수에 대응하기 어렵습니다. Overfitting은 보통 모델이 너무 복잡할 때 발생합니다. 특히 딥러닝은 학습 단계에서 입력, 은닉층, 출력층의 노드들에 상당히 많은 변수들이 투입되기 때문에 Overfitting이 발생할 위험이 큽니다. Overfitting이 발생하면 이 모델은 Training Data에 대해서는 매우 정확하지만 훈련되지 않은 새로운 데이터에 대해서는 정확성이 떨어집니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BXuSxBWZk3HY"
   },
   "source": [
    "### Underfitting(과소적합)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YCw6lXwDk3HZ"
   },
   "source": [
    "Overfitting과 반대로, Underfitting은 모델이 Training Data에 잘 맞지 않아서 데이터의 내재된 구조를 학습하지 못할 때 발생하는 문제입니다. Underfitting도 Overfitting과 마찬가지로 새로운 데이터에 일반화될 수 없습니다. 보통 모델이 너무 단순할 때 발생합니다. 예를 들어, 위의 왼쪽 그림처럼 선형이 아닌 데이터에 대해 선형 모델을 학습시킬 때 Underfitting이 발생할 수 있습니다. <br>\n",
    "\n",
    "그렇다면 Overfitting과 Underfitting을 방지하려면 어떻게 해야 할까요? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cGnFHXUmk3Ha"
   },
   "source": [
    "## Bias(편향)와 Variance(분산)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2lbFpiDok3Hb"
   },
   "source": [
    "모델 예측을 논의할 때, Bias와 Variance를 이해하는 것이 중요합니다. Bias와 Variance는 Trade-off 관계에 있기 때문에 이 둘을 모두 최소화시키는 것은 불가능합니다. 이 두 가지 에러를 적절히 이해하면 정확한 모델을 만들 수 있을 뿐만 아니라 Overfitting과 Underfitting을 피할 수 있습니다. <br>\n",
    "\n",
    "머신러닝/딥러닝 모델에서 이 두 가지 에러의 개념과 차이를 살펴봅시다. <br>\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=1xrQc3y3HPtm3bJlBiG8OGWBCjuOv1BOg\" width=\"600\"> <br>\n",
    "\n",
    "우리가 예측하고자 하는 변수를 Y라고 하고 학습에 사용되는 데이터인 독립변수(Feature)을 X라고 합시다. 두 변수 사이에는 다음과 같은 관계가 존재한다고 가정합니다. <br>\n",
    "$$ Y=f(X) + e $$ <br>\n",
    "여기서 e는 에러 항을 의미하며, e는 평균이 0인 정규분포를 따릅니다. <br>\n",
    "따라서 x에서의 Total Error는 다음과 같습니다. 여기서 $\\hat{f}(x)$ 은 예측값을 의미합니다.<br>\n",
    "$$ Total Error(x) = E[(Y-\\hat{f}(x))^2] $$ <br>\n",
    "Total Error(x)는 다음과 같이 분해될 수 있습니다. <br>\n",
    "$$ Total Error(x) = (E[\\hat{f}(x)]-f(x))^2 + E[(\\hat{f}(x)-E[\\hat{f}(x)])^2] + \\sigma_{e}^2$$ \n",
    "$$ Total Error(x) = Bias^2 + Variance + Irreducible Error $$ <br>\n",
    "Irreducible Error는 좋은 모델을 생성함으로써 줄일 수 없는 에러입니다. 이는 데이터가 가진 noise에 대한 척도입니다. 모델의 적합성에 관계없이 데이터는 특정량의 noise(또는 Irreducible Error)를 가지고 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kYOaOvp7k3Hc"
   },
   "source": [
    "### Bias(편향)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "35THTJjwk3He"
   },
   "source": [
    "Bias는 모델의 예측값과 실제값의 차이를 의미합니다. 즉, 위의 그림에서 볼 수 있듯이 예측값이 실제값에 얼마나 가까운지를 나타냅니다. 높은 Bias를 가진 모델은 Training Data에 거의 관심을 기울이지 않고 모델을 지나치게 단순화합니다. 이는 항상 훈련 데이터와 테스트 데이터에서 높은 에러를 초래합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OR6FFBXFk3Hf"
   },
   "source": [
    "### Variance(분산)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9jgTdCOKk3Hg"
   },
   "source": [
    "Variance는 주어진 데이터에 대한 모델의 예측값들이 서로 얼마나 퍼져 있는지에 대한 척도입니다. 높은 Variance를 가진 모델은 Training Data에 너무 관심을 기울여서 전에 보지 못한 데이터들에 일반화할 수 없습니다. 결과적으로, 그러한 모델은 Training Data에 대해서는 성능이 좋지만, Testing Data에 대해서는 높은 에러를 보여줍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SBZ97b9Vk3Hh"
   },
   "source": [
    "### Bias와 Variance의 Tradeoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bkYdtBXok3Hi"
   },
   "source": [
    "Bias-Variance Tradeoff라는 개념은 간단하게 말하면 Bias와 Variance는 어쩔 수 없이 서로 trade-off 관계를 가지고 있다는 의미입니다. 모델을 선택할 때, Training Data의 패턴을 정확하게 파악하는 것뿐만 아니라 새로운 데이터에까지 일반화될 수 있도록 하는 것이 가장 이상적인 바람입니다. 하지만 이 둘을 동시에 만족시키는 것은 사실상 불가능합니다. 모델이 너무 단순하거나 패러미터가 너무 적으면 높은 Bias와 낮은 Variance를 가질 것입니다. 반면 우리 모델이 패러미터가 많으면 높은 Variance와 낮은 Bias를 가질 것입니다. 위에서 구한 식에서도 Bias와 Variance 중 하나가 높으면 다른 하나는 낮을 수밖에 없습니다. 그래서 Bias와 Variance 사이의 균형점을 잘 찾는 것이 중요합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZP93wHJDk3Hj"
   },
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-QUgRNkqk3Hk"
   },
   "source": [
    "### Validation Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jqjVBT5ek3Hl"
   },
   "source": [
    "머신러닝/딥러닝의 모델에서는 전체 데이터를 Training Data로 학습한 뒤, Testing Data로 예측하는 과정을 거칩니다. <br>\n",
    "\n",
    "그렇다면 Validation Set은 무엇이며, 왜 필요할까요? Validation Set을 통해 우리는 모델의 성능을 대략적으로 파악할 수 있습니다. Training Data의 일부를 떼어낸 후, 남은 부분을 학습한 뒤, 모델을 통해 떼어낸 부분에 대한 예측을 도출합니다. 이 떼어낸 부분을 Validation Set이라고 합니다. 우리는 이 Validation Set 의 실제 값(정답)을 알고 있기 때문에 예측치와 비교하여 모델의 성능을 평가할 수 있습니다. 그러니 Validation Set은 모의고사 문제라고 보시면 됩니다. <br>\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=1gbvCf6oCWmAVv4oMZVw46R3x6kcaEIB1\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z-ewqa1Tk3Hm"
   },
   "source": [
    "### 홀드아웃 검증(Hold-out Validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TMj1je0Sk3Hn"
   },
   "source": [
    "과대적합을 방지하기 위한 한 가지 방법으로, 먼저 학습을 위한 Training Data 중 일부를 Validation Set으로 떼어내어 모델의 예측력을 테스트하는 데 사용합니다. <br>\n",
    "\n",
    "이를 어떻게 사용하는지 살펴봅시다. 먼저 필요한 라이브러리들을 import합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7Ofa75kUk3Ho"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.JPIJNSWNNAN3CE6LLI5FWSPHUT2VXMTH.gfortran-win_amd64.dll\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jW4iVO9Sk3Hs"
   },
   "source": [
    "import한 라이브러리에 대해 빠르게 알아봅시다.\n",
    "- pandas: data 파일을 Pandas 데이터프레임으로 로드하고 분석합니다. Pandas에 대해 더 알아보고 싶다면 해당 [링크](https://pandas.pydata.org/pandas-docs/stable/)를 클릭하세요.\n",
    "- numpy: Numpy의 random 모듈을 이용하여 데이터를 랜덤하게 생성 또는 변형합니다. Numpy에 대해 더 알아보고 싶다면 해당 [링크](https://docs.scipy.org/doc/numpy/reference/)를 클릭하세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qOArLLG6k3Ht"
   },
   "source": [
    "이번에 사용할 데이터셋은 **붓꽃(iris, 아이리스) 데이터셋**입니다. 이 데이터는 사이킷런(Scikit-learn, sklearn)의 datasets 모듈에 포함되어 있습니다. <br>\n",
    "\n",
    "붓꽃의 종류는 크게 **3가지**, **iris setosa** / **iris versicolor** / **iris virginica**가 존재하며, 주어진 꽃잎과 꽃받침의 길이와 너비를 활용해 해당 꽃의 종류를 구분합니다. 각 컬럼에 대한 설명은 다음과 같습니다.\n",
    "\n",
    "  * **sepal length (cm)**: 꽃받침의 길이\n",
    "  * **sepal width (cm)**: 꽃받침의 너비\n",
    "  * **petal length (cm)**: 꽃잎의 길이\n",
    "  * **petal width (cm)**: 꽃잎의 너비\n",
    "  * **species**: 붓꽃의 종류. iris setosa(0) / iris versicolor(1) / iris virginica(2) 의 세 종류가 있다.\n",
    "  \n",
    "이제 사이킷런의 load_iris 함수를 사용하여 데이터셋을 로드하겠습니다. load_iris가 반환한 iris 객체는 파이썬의 딕셔너리(Dictionary)와 유사한 Bunch 클래스의 객체입니다. 즉, 키와 값으로 구성되어 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9AooYIjak3Hu",
    "outputId": "7382c0a8-4299-4d35-a847-2a6c9f160e46"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 사이킷런의 load_iris를 불러옵니다.\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# load_iris를 이용하여 데이터를 가져옵니다.\n",
    "iris = load_iris()\n",
    "\n",
    "# keys()를 이용하여 iris 데이터에서 어떤 키들을 사용할 수 있는지 확인해봅시다.\n",
    "iris.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_qyOUPWdk3Hy"
   },
   "source": [
    "target_names는 우리가 예측하려는 붓꽃 종류의 이름, feature_names는 각 feature, data는 꽃잎의 길이와 너비, 꽃받침의 길이와 너비를 수치값으로 가지고 있는 넘파이(Numpy) 배열입니다. target은 붓꽃의 종류를 0에서 2까지의 정수로 기록한 넘파이 배열입니다. 0은 setosa, 1은 versicolor, 2는 virginica입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yjxJRwk8k3Hz",
    "outputId": "d61822ee-e5cd-4177-ffb1-bf490a586403",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_names: ['setosa' 'versicolor' 'virginica']\n",
      "feature_names: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "data's shape: (150, 4)\n",
      "target's shape: (150,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>species</th>\n",
       "      <th>species(humanized)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   species species(humanized)  \n",
       "0        0             setosa  \n",
       "1        0             setosa  \n",
       "2        0             setosa  \n",
       "3        0             setosa  \n",
       "4        0             setosa  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target_names를 출력하여 예측하고자 하는 붓꽃 종류의 이름을 확인합니다.\n",
    "print('target_names:', iris['target_names'])\n",
    "\n",
    "# feature_names를 출력하여 예측을 위해 어떤 feature를 사용할 수 있는지 확인합니다.\n",
    "print('feature_names:', iris['feature_names'])\n",
    "\n",
    "# feature의 값들을 가지고 있는 data의 형태를 출력합니다.\n",
    "print('data\\'s shape:', iris['data'].shape)\n",
    "\n",
    "# 예측하고자 하는 target 값들의 형태를 출력합니다. \n",
    "print('target\\'s shape:', iris['target'].shape)\n",
    "\n",
    "# iris 데이터셋을 판다스의 DataFrame으로 출력합니다.\n",
    "iris_df = pd.DataFrame(iris['data'], columns=iris['feature_names'])\n",
    "\n",
    "# 종에 대한 정보를 species라는 컬럼에 추가합니다.\n",
    "iris_df['species'] = iris['target']\n",
    "\n",
    "# 0, 1, 2의 숫자로 기록된 붓꽃 종류에 대한 정보를 실제 붓꽃 종류의 이름으로 대체하여 출력합니다.\n",
    "iris_df['species(humanized)'] = iris_df['species'].replace(0, iris['target_names'][0]).replace(1, iris['target_names'][1]).replace(2, iris['target_names'][2])\n",
    "\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v4Cg2-Y8k3H2"
   },
   "source": [
    "예측에 필요한 feature를 X에, target을 y에 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MWmAajjMk3H3"
   },
   "outputs": [],
   "source": [
    "X = iris['data']\n",
    "y = iris['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vbrYRiYrk3H6"
   },
   "source": [
    "데이터셋으로부터 학습을 위한 Training Data와 최종적으로 성능을 평가할 Testing Data로 나누겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R0t3575Tk3H7",
    "outputId": "27110040-64a0-4125-81c6-ad9939b37e43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 4) (120,)\n",
      "(30, 4) (30,)\n"
     ]
    }
   ],
   "source": [
    "# 총 범주의 수를 가져옵니다. 150이 될 것입니다.\n",
    "n_samples = len(X)\n",
    "\n",
    "# 데이터의 index로 사용할 Numpy 배열을 정의합니다. \n",
    "indices = np.arange(n_samples)\n",
    "\n",
    "# 코드를 실행할 때마다 랜덤으로 값이 만들어지기 때문에 결과를 고정하기 위해 seed를 고정합니다.\n",
    "np.random.seed = 123\n",
    "\n",
    "# indices의 순서를 섞어줍니다.\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "# Testing Data의 비율을 20%로 설정하겠습니다.\n",
    "test_ratio = 0.2\n",
    "train_size = int(n_samples * (1 - test_ratio))\n",
    "\n",
    "# Training Data로 사용할 index와 Testing Data로 사용할 index를 구분합니다.\n",
    "train_idx = indices[:train_size]\n",
    "test_idx = indices[train_size:]\n",
    "\n",
    "# 위에서 만든 index를 이용하여 Training Data와 Testing Data로 나누어줍니다.\n",
    "X_train = X[train_idx]\n",
    "y_train = y[train_idx]\n",
    "X_test = X[test_idx]\n",
    "y_test = y[test_idx]\n",
    "\n",
    "# 80:20으로 나눈 Training Data와 Testing Data의 형태를 출력하여 제대로 나누어졌는지 확인합니다.\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BBG0Ubr1k3H-"
   },
   "source": [
    "#### Hold-out Validation 직접 짜보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WbWEyGYdk3H_",
    "outputId": "c355ecec-6e50-40d5-d2cd-09372f6b161a"
   },
   "outputs": [],
   "source": [
    "# Write your code!\n",
    "\n",
    "n_samples = len(X_train)\n",
    "\n",
    "indices = np.arange(n_samples)\n",
    "\n",
    "np.random.seed = 123\n",
    "\n",
    "np.random.shuffle(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_ratio = 0.2\n",
    "train_size = int(n_samples * (1 - validation_ratio))\n",
    "\n",
    "train_idx = indices[:train_size]\n",
    "validation_idx = indices[train_size:]\n",
    "\n",
    "X_train_fold = X_train[train_idx]\n",
    "y_train_fold = y_train[train_idx]\n",
    "X_validation_fold = X_train[validation_idx]\n",
    "y_validation_fold = y_train[validation_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96, 4) (96,)\n",
      "(24, 4) (24,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_fold.shape, y_train_fold.shape)\n",
    "print(X_validation_fold.shape, y_validation_fold.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0wH7XujTk3IB"
   },
   "source": [
    "#### 사이킷런의 train_test_split 이용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wi-2wFHgk3IC"
   },
   "source": [
    "이제 사이킷런의 train_test_split 함수를 이용하여 dataset를 나누어봅시다. 함수 내 **test_size**는 원본 데이터로부터 떼어낼 데이터의 비율을 가리킵니다. 보통 82/20 또는 70/30을 사용하며, 아래에서는 Training Data를 80%, Testing Data를 20%로 설정하였습니다. 이렇게 만든 Training Data에서 Validation Set의 비율을 20%로 설정하였습니다. 이 함수를 여러 번 실행해도 결과가 똑같이 나오도록 random_state 매개변수를 123으로 고정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LWn9oZXXk3ID",
    "outputId": "60c2f854-7060-4b24-dfa8-4743866bc721"
   },
   "outputs": [],
   "source": [
    "# 사이킷런의 train_test_split를 불러옵니다. \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train_test_split을 이용하여 iris 데이터를 Training Data와 Testing Data로 나누어줍니다.\n",
    "# Write your code!\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 123)\n",
    "\n",
    "\n",
    "# train_test_split을 이용하여 Training Data에서 Validation Set을 떼어냅니다.\n",
    "# Write your code!\n",
    "X_train_fold, X_validation_fold, y_train_fold, y_validation_fold = train_test_split(X_train, y_train, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96, 4) (24, 4)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_fold.shape, X_validation_fold.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2mxIFgUFk3IG"
   },
   "source": [
    "### 교차 검증(Cross Validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SNuOtnPrk3IH"
   },
   "source": [
    "#### K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EWukIhMWk3II"
   },
   "source": [
    "K-Fold Cross Validation에서는 데이터를 k개의 서로 다른 subset(fold)들로 나눕니다. 그리고 k-1개의 subset들을 Training Set에 사용하고 나머지 subset 하나를 Validation Set으로 사용합니다. 그럼, 총 k 번 만큼 Model Evaluation을 진행할 수 있고, 총 k번의 Model Evaluation한 결과에 평균을 내면 이 모델의 성능을 측정할 수 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fGn7u_jvk3IJ"
   },
   "source": [
    "#### K-Fold 직접 짜보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 총 범주의 수를 가져옵니다. 120이 될 것입니다.\n",
    "n_samples = len(X_train)\n",
    "\n",
    "# Training Data의 index로 사용할 Numpy 배열을 정의합니다.\n",
    "indices = np.arange(n_samples)\n",
    "\n",
    "# 코드를 실행할 때마다 랜덤으로 값이 만들어지기 때문에 결과를 고정하기 위해 seed를 고정합니다.\n",
    "np.random.seed = 123\n",
    "\n",
    "# indices의 순서를 섞어줍니다.\n",
    "np.random.shuffle(indices)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-nEa36FZk3IO",
    "outputId": "db0f97c5-2645-46d6-f41a-bfa71c721a63"
   },
   "outputs": [],
   "source": [
    "# Write your code!\n",
    "\n",
    "n_splits = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24, 24, 24, 24, 24])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold_sizes = np.full(n_splits, n_samples // n_splits)\n",
    "fold_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_sizes[-1] += n_samples % n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_indices = []\n",
    "\n",
    "start_idx = 0\n",
    "\n",
    "for i in range(n_splits):\n",
    "    stop_idx = start_idx + fold_sizes[i]\n",
    "    \n",
    "    fold_indices.append(indices[start_idx:stop_idx])\n",
    "    fold_indices[i].sort()\n",
    "    \n",
    "    start_idx += fold_sizes[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "train_fold 사이즈 ((96, 4), (96,))\n",
      "validation_fold 사이즈 ((24, 4), (24,))\n",
      "validation_fold 인덱스 [ 12  15  19  20  26  27  28  33  36  38  44  61  62  65  67  76  79  81\n",
      "  94  95  99 106 107 111]\n",
      "--------------------------------------------------\n",
      "train_fold 사이즈 ((96, 4), (96,))\n",
      "validation_fold 사이즈 ((24, 4), (24,))\n",
      "validation_fold 인덱스 [  4   6   8  10  11  23  25  43  46  48  50  51  54  55  59  68  72  74\n",
      "  84  85  91 109 110 112]\n",
      "--------------------------------------------------\n",
      "train_fold 사이즈 ((96, 4), (96,))\n",
      "validation_fold 사이즈 ((24, 4), (24,))\n",
      "validation_fold 인덱스 [  1   7  29  31  34  45  53  56  57  58  60  70  71  73  83  88  89  90\n",
      "  92  93  96 102 116 118]\n",
      "--------------------------------------------------\n",
      "train_fold 사이즈 ((96, 4), (96,))\n",
      "validation_fold 사이즈 ((24, 4), (24,))\n",
      "validation_fold 인덱스 [  0   3   5  13  17  30  37  39  40  41  42  49  66  75  80  86  97 100\n",
      " 103 104 105 114 117 119]\n",
      "--------------------------------------------------\n",
      "train_fold 사이즈 ((96, 4), (96,))\n",
      "validation_fold 사이즈 ((24, 4), (24,))\n",
      "validation_fold 인덱스 [  2   9  14  16  18  21  22  24  32  35  47  52  63  64  69  77  78  82\n",
      "  87  98 101 108 113 115]\n"
     ]
    }
   ],
   "source": [
    "n_iter = 0\n",
    "\n",
    "for i in range(n_splits):\n",
    "    \n",
    "    validation_idx = fold_indices[i]\n",
    "    \n",
    "    train_idx = np.setdiff1d(indices, validation_idx)\n",
    "    \n",
    "    X_train_fold, X_validation_fold = X_train[train_idx], X_train[validation_idx]\n",
    "    y_train_fold, y_validation_fold = y_train[train_idx], y_train[validation_idx]\n",
    "    \n",
    "    n_iter += 1\n",
    "    \n",
    "    print('-'*50)\n",
    "    print(f'train_fold 사이즈 {X_train_fold.shape, y_train_fold.shape}')\n",
    "    print(f'validation_fold 사이즈 {X_validation_fold.shape, y_validation_fold.shape}')\n",
    "    print(f'validation_fold 인덱스 {validation_idx}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7NK73TGfk3IS"
   },
   "source": [
    "#### 사이킷런의 KFold 이용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eFCiNMzzk3IT"
   },
   "source": [
    "사이킷런에서는 데이터셋을 k개의 연속적인 fold로 나누어주는 **KFold()**를 제공합니다. KFold의 파라미터로는 n_splits와 shuffle, random_state가 있습니다.\n",
    "- n_splits : fold의 개수. 2 이상의 정수를 입력해야 하며, 초기 설정값은 5입니다. \n",
    "- shuffle : 데이터셋을 나누기 전에 데이터를 섞을지를 결정하며, 초기 설정값은 False입니다. \n",
    "- random_state : shuffle 파라미터의 값을 True로 설정했을 때 랜덤 생성 seed를 설정할 수 있습니다. <br>\n",
    "\n",
    "KFold의 split() 함수는 파라미터로 입력한 데이터의 인덱스를 Training Set과 Testing Set으로 나누어줍니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sHBn43sOk3IU",
    "outputId": "3d03cf3b-7f47-4eda-bf57-d49aa95fe9a2"
   },
   "outputs": [],
   "source": [
    "# 사이킷런의 KFold를 불러옵니다.\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Write your code!\n",
    "kfold = KFold(n_splits = 5, shuffle = True, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "train_fold 사이즈 ((96, 4), (96,))\n",
      "validation_fold 사이즈 ((24, 4), (24,))\n",
      "validation_fold 인덱스 [  0   4   5   8  13  16  24  29  31  33  35  51  56  62  65  72  77  85\n",
      "  87  94 104 110 112 117]\n",
      "--------------------------------------------------\n",
      "train_fold 사이즈 ((96, 4), (96,))\n",
      "validation_fold 사이즈 ((24, 4), (24,))\n",
      "validation_fold 인덱스 [  9  19  21  23  28  38  41  42  44  45  53  59  60  63  71  74  79  93\n",
      "  99 100 105 111 116 119]\n",
      "--------------------------------------------------\n",
      "train_fold 사이즈 ((96, 4), (96,))\n",
      "validation_fold 사이즈 ((24, 4), (24,))\n",
      "validation_fold 인덱스 [  1   6  11  12  14  15  18  20  22  26  30  37  43  50  54  70  82  88\n",
      "  89  90  95 101 114 115]\n",
      "--------------------------------------------------\n",
      "train_fold 사이즈 ((96, 4), (96,))\n",
      "validation_fold 사이즈 ((24, 4), (24,))\n",
      "validation_fold 인덱스 [  2   3   7  10  27  34  39  40  48  49  52  55  58  61  64  67  69  75\n",
      "  76  81  84  91 107 118]\n",
      "--------------------------------------------------\n",
      "train_fold 사이즈 ((96, 4), (96,))\n",
      "validation_fold 사이즈 ((24, 4), (24,))\n",
      "validation_fold 인덱스 [ 17  25  32  36  46  47  57  66  68  73  78  80  83  86  92  96  97  98\n",
      " 102 103 106 108 109 113]\n"
     ]
    }
   ],
   "source": [
    "for train_idx, validation_idx in kfold.split(X_train):\n",
    "    \n",
    "    X_train_fold, X_validation_fold = X_train[train_idx], X_train[validation_idx]\n",
    "    y_train_fold, y_validation_fold = y_train[train_idx], y_train[validation_idx]\n",
    "    \n",
    "    print('-'*50)\n",
    "    print(f'train_fold 사이즈 {X_train_fold.shape, y_train_fold.shape}')\n",
    "    print(f'validation_fold 사이즈 {X_validation_fold.shape, y_validation_fold.shape}')\n",
    "    print(f'validation_fold 인덱스 {validation_idx}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vza0x2Qek3IX"
   },
   "source": [
    "## 측정 공식 (성능 평가 지표, Evaluation Metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cCGHzn7ak3IY"
   },
   "source": [
    "## 1) 측정 공식 - 분류 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B2IwGwjJk3IZ"
   },
   "source": [
    "### 오차행렬(Confusion Matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rak6ez5fk3Ia"
   },
   "source": [
    "이진 분류 모델의 성능을 평가하는 방법으로 잘 활용되는 방법은 Confusion Matrix를 만들어보는 것입니다. Confusion Matrix는 다음과 같은 2x2 행렬에서 실제값과 예측값이 어떻게 매핑되는지를 나타냅니다. \n",
    "\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=1bcJ-dYqnocfV7EOs7nXAJ9cWq1Oq5BWd\" width=\"800\">\n",
    "\n",
    "\n",
    "이진 분류에서 사용하는 용어 중 \"**positive**\"와 \"**negative**\"는 모델이 내놓은 예측값 기준으로 분류한 것이고, \"**true**\"와 \"**false**\"는 예측값과 실제값의 일치 여부를 기준으로 분류한 것입니다. 각 경우별로 살펴본다면 다음과 같습니다. <br>\n",
    "- True Negative(TN): 실제 False인 값을 False라고 예측 (정답)\n",
    "- False Positive(FP): 실제 False인 값을 True라고 예측 (오답)\n",
    "- False Negative(FN): 실제 True인 값을 False라고 예측 (오답)\n",
    "- True Positive(TP): 실제 True인 값을 True라고 예측 (정답) <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "evnfPQSdk3Ib"
   },
   "source": [
    "우선, 분류 모델에 대한 측정 공식을 알아보기 위한 예제 데이터셋을 랜덤으로 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8btgwg9sk3Ic",
    "outputId": "52c039b3-967c-4eb3-f2fb-f5a5f39c2aae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20,)\n",
      "(20,)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 1 0]\n",
      "[0 0 1 0 0 0 1 1 1 0 1 0 1 0 0 0 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# numpy를 사용하여 랜덤한 값을 만들 것입니다. \n",
    "# numpy의 random(np.random)은 랜덤 값을 생성하는 기능들을 포함하고 있습니다. \n",
    "# 코드를 실행할 때마다 랜덤으로 값이 만들어지기 때문에 결과를 고정하기 위해 seed를 고정합니다.\n",
    "np.random.seed = 123\n",
    "\n",
    "# np.random.randint()는 최솟값(low), 최대값(high), 개수(size)를 입력받습니다. \n",
    "# 최솟값과 최댓값 사이에서 지정한 개수만큼 랜덤하게 정수(Integer)를 추출합니다.\n",
    "y_true = np.random.randint(low=0, high=2, size=20)\n",
    "y_pred = np.random.randint(low=0, high=2, size=20)\n",
    "\n",
    "# y_true와 y_pred의 shape를 확인합니다.\n",
    "# 20개가 잘 뽑혔다면 (20, 1) 또는 (20, )이 출력됩니다.\n",
    "print(y_true.shape)\n",
    "print(y_pred.shape)\n",
    "\n",
    "# y_true와 y_pred의 값을 확인합니다.\n",
    "print(y_true)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6iBbXVU3k3If"
   },
   "source": [
    "사이킷런은 Confusion Matrix를 만드는 **confusion_matrix()** API를 제공합니다. 실제값인 y_true와 예측값인 y_pred를 confusion_matrix()의 인자로 입력합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qDilyGynk3If",
    "outputId": "91064f93-0946-4ad5-df12-d193320971b6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8, 8],\n",
       "       [3, 1]], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 사이킷런의 confusion_matrix를 불러옵니다.\n",
    "# Evaluation Metric과 관련된 함수는 사이킷런의 metrics에 포함되어 있습니다.\n",
    "# Write your code!\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xm7lf4Zwk3Ih"
   },
   "source": [
    "출력된 Confusion Matrix은 array 형태입니다. 이진 분류의 TN, FP, FN, TP는 위의 표에서와 위치가 같습니다. 즉, TN은 array[0,0], FP는 array[0,1], FN은 array[1,0], TP는 array[1,1]에 해당합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vmoBpv3Uk3Ii",
    "outputId": "fbe8b8e1-c7e3-4361-c7a0-c828214ad5e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 8 3 1\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix의 각 요소를 가져와봅시다. \n",
    "# Write your code!\n",
    "\n",
    "tn = confusion_matrix(y_true, y_pred)[0, 0]\n",
    "fp = confusion_matrix(y_true, y_pred)[0, 1]\n",
    "fn = confusion_matrix(y_true, y_pred)[1, 0]\n",
    "tp = confusion_matrix(y_true, y_pred)[1, 1]\n",
    "\n",
    "print(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VDRtvw22k3Il"
   },
   "source": [
    "### 정확도(Accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "69RWG_2Ek3Il"
   },
   "source": [
    "Accuracy는 실제값과 예측값이 얼마나 같은지를 판단하는 지표입니다. 즉, Confusion Matrix에서 True에 해당하는 값인 **TN**과 **TP**에 좌우됩니다. Accuracy는 Confusion Matrix와 관련하여 다음과 같이 정의될 수 있습니다.\n",
    "$$ Accuracy = \\frac{예측값과 실제값이 일치하는 데이터 수}{전체 데이터 수} = \\frac{TN + TP}{TN + FP + FN + TP}$$ \n",
    "\n",
    "Accuracy를 구하는 기능은 다음과 같이 구현할 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PfBYrNZWk3Im",
    "outputId": "8bbc86eb-088a-4d1b-e4cf-9f531198788d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code!\n",
    "\n",
    "n_correct = sum(y_true == y_pred)\n",
    "\n",
    "accuracy_1 = n_correct / len(y_pred)\n",
    "accuracy_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mx4J8ohsk3Iq"
   },
   "source": [
    "사이킷런은 Accuracy를 측정하는 **accuracy_score()** 함수를 제공합니다. 첫 번째 파라미터로 실제값, 두 번째 파라미터로 예측값을 입력하면 됩니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zMz--Laqk3Ir",
    "outputId": "6c9221b5-85c1-493d-89a8-953748105ff1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code!\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_2 = accuracy_score(y_true, y_pred)\n",
    "accuracy_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_true == y_pred).mean(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2buV-dBfk3It"
   },
   "source": [
    "그러나, **불균형한 데이터 세트**에서는 Accuracy만으로는 모델 신뢰도가 떨어질 수 있습니다. 예를 들어, 전체 데이터가 100개라고 할 때 10개만 1, 나머지 90개는 0인 데이터 세트가 있다고 가정합시다. 이 데이터 세트에 모든 데이터를 0으로 예측하는 모델을 이용해 Accuracy를 측정하면 90%의 Accuracy를 나타냅니다. 적절하지 않은 모델을 사용하고도 높은 수치가 나타날 수 있다는 것이 Accuracy를 평가 지표로 사용할 때의 문제점입니다. <br>\n",
    "\n",
    "불균형한 데이터 세트에서 Accuracy의 이러한 **단점을 보완**할 수 있는 평가 지표로 정밀도(Precision)와 재현율(Recall)이 있습니다. Precision와 Recall은 \"**positive**\" 데이터 세트의 예측 성능에 좀더 초점을 맞춘 평가 지표입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cFiuz37xk3It"
   },
   "source": [
    "### 정밀도(Precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ts_E-EY0k3Iu"
   },
   "source": [
    "Precision는 \"positive\"로 예측한 대상 중에 예측값과 실제값이 일치하는 데이터의 비율을 말합니다. 따라서 Precision이 높을수록 좋은 모형입니다. Precision는 Confusion Matrix와 관련하여 다음과 같이 정의될 수 있습니다. \n",
    "$$Precision = \\frac{TP}{FP + TP} $$\n",
    "\n",
    "Precision을 구하는 기능은 다음과 같이 구현할 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SKhibsP9k3Iw",
    "outputId": "ac6a0375-06c4-4f31-fc10-c118ec1ba21c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1111111111111111"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code!\n",
    "\n",
    "precision = tp / (fp + tp)\n",
    "\n",
    "precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pulF5OKMk3Iy"
   },
   "source": [
    "사이킷런은 Precision을 계산하는 **precision_score()** 함수를 제공합니다. 첫 번째 파라미터로 실제값, 두 번째 파라미터로 예측값을 입력하면 됩니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sf27pc59k3Iz",
    "outputId": "9f04b980-348e-4948-c92b-8d15cdd61260"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1111111111111111"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code!\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision_2 = precision_score(y_true, y_pred)\n",
    "precision_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qhJ5ThJMk3I1"
   },
   "source": [
    "### 재현율(Recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m24LeOWbk3I2"
   },
   "source": [
    "Recall은 실제값이 \"positive\"인 대상 중에 예측값과 실제값이 일치하는 데이터의 비율을 말합니다. 따라서 Recall이 높을수록 좋은 모형입니다. Recall은 민감도(Sensitivity) 또는 TPR(True Positive Rate)라고도 불립니다. Recall은 Confusion Matrix와 관련하여 다음과 같이 정의될 수 있습니다.\n",
    "$$ Recall = \\frac{TP}{FN + TP} $$\n",
    "\n",
    "Recall을 구하는 기능은 다음과 같이 구현할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_L23CQYUk3I3",
    "outputId": "c591c941-c29b-423b-89bd-3b5697f4605a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code!\n",
    "\n",
    "recall = tp / (fn + tp)\n",
    "recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YZ4kcreLk3I6"
   },
   "source": [
    "사이킷런은 재현율을 계산하는 **recall_score()** 함수를 제공합니다. 첫 번째 파라미터로 실제값, 두 번째 파라미터로 예측값을 입력하면 됩니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wt2x-CN0k3I7",
    "outputId": "e99f3862-db54-48d7-d61d-ba6b72a98621"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code!\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "recall_2 = recall_score(y_true, y_pred)\n",
    "recall_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oBGFi1C4k3I-"
   },
   "source": [
    "상황에 따라 Precision이 더 중요할 수도 있고 Recall이 더 중요한 지표가 될 수도 있습니다. <br>\n",
    "\n",
    "실제 \"negative\"인 데이터를 \"positive\"로 잘못 판단했을 때 업무상 큰 영향을 주는 경우에는 Precision이 상대적으로 더 중요한 지표가 됩니다. 반대로 실제 \"positive\"인 데이터를 \"negative\"로 잘못 판단했을 때 업무상 큰 영향을 주는 경우에는 Recall이 상대적으로 더 중요한 지표가 됩니다. <br>\n",
    "\n",
    "예를 들어 스팸 메일 여부를 판단하는 모델의 경우, 실제 스팸 메일(positive)인데 일반 메일(negative)로 분류한다면 사용자는 불편함을 느끼는 정도일 것입니다. 그러나 실제로 중요한 일반 메일(negative)를 스팸 메일(positive)로 분류하는 경우 업무에 차질이 생기게 될 것입니다. 이때에는 Precision이 더 중요한 지표가 됩니다. <br>\n",
    "\n",
    "다른 예로, 암 환자를 판단하는 모델에서는 Recall이 더 중요한 지표가 됩니다. 실제로 암 환자(positive)인데 암 환자가 아니라고(negative) 판단하는 경우에 제때 치료를 받지 못하게 되므로 심각한 문제를 일으킬 수 있습니다. 반면 실제로 암 환자가 아닌(negative) 경우에 암 환자(positive)인 것으로 잘못 판단되는 경우에는 재검사 비용이 소모되기는 하겠지만 생명을 앗아가지는 않을 것입니다. <br>\n",
    "\n",
    "Precision와 Recall의 공식을 살펴보면, 두 지표 모두 TP를 높이는 데 동일하게 초점을 맞추지만, Precision은 FP를, Recall은 FN을 낮추는 데 초점을 맞춥니다. 이러한 특성 때문에 Precision와 Recall은 분류의 성능을 평가하는 데 있어서 서로 보완적으로 작용합니다. <br>\n",
    "\n",
    "따라서 Precision와 Recall 중 어느 하나만 매우 높고 다른 수치는 매우 낮은 결과를 나타내는 경우 바람직하지 않습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gLgjT_hnk3I-"
   },
   "source": [
    "### F1 스코어(F1 Score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kka_TuTpk3I_"
   },
   "source": [
    "**F 스코어**는 **Precision**과 **Recall**의 **가중조화평균**으로, Precision에 주어지는 가중치를 베타(Beta)라고 합니다. Precision과 Recall을 결합한 지표로 분류의 종합적인 성능 평가에 사용될 수 있습니다. \n",
    "$$ F_β=\\frac{(1+β^2)(Precision*Recall)}{β^2Precision+Recall} $$\n",
    "\n",
    "베타가 1인 경우를 특별히 F1 스코어라고 합니다. F1 스코어는 Precision와 Recall이 어느 한쪽으로 치우치지 않을 때 상대적으로 높은 값을 가집니다. \n",
    "$$ F1 = \\frac{2}{\\frac{1}{Recall}+\\frac{1}{Precision}} = \\frac{2*Precision*Recall}{Precision + Recall} $$ \n",
    "\n",
    "f1 score을 구하는 기능은 다음과 같이 구현할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wc9ZmJXpk3JA",
    "outputId": "43eebe31-b6ec-45e2-fba0-799b9e129ecd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15384615384615383"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code!\n",
    "\n",
    "f1_1 = (2 * precision * recall) / (precision + recall)\n",
    "f1_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CdZ1RVcAk3JD"
   },
   "source": [
    "사이킷런은 F1 스코어를 구하는 **f1_score()**라는 API를 제공합니다. 첫 번째 파라미터로 실제값, 두 번째 파라미터로 예측값을 입력하면 됩니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HdSKDqSBk3JE",
    "outputId": "a8ab1065-907f-4cf9-bdd4-57eb652abadb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15384615384615383"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code!\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_2 = f1_score(y_true, y_pred)\n",
    "f1_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jlx6k_k0k3JG"
   },
   "source": [
    "사이킷런의 metrics 패키지에서는 Precision, Recall, F1 스코어를 포함한 주요 분류 측정 공식을 구하는 **classification_report()** 함수를 제공합니다. 이 함수는 딕셔너리 형태의 결과값을 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V6UzM04yk3JI",
    "outputId": "e40b13c6-61b7-43fd-ed9c-f4f5ff4acdcf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.50      0.59        16\n",
      "           1       0.11      0.25      0.15         4\n",
      "\n",
      "    accuracy                           0.45        20\n",
      "   macro avg       0.42      0.38      0.37        20\n",
      "weighted avg       0.60      0.45      0.50        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Write your code!\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1yQ-5vKqk3JL"
   },
   "source": [
    "### ROC 곡선과 AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ri7_Iumok3JL"
   },
   "source": [
    "ROC 곡선과 AUC에 대해 설명하기 이전에 일단 다음 두 가지 개념에 대해 먼저 알아보겠습니다. <br>\n",
    "위에서 설명한 **재현율(Recall)**은 참 양성 비율(True Positive Rate, **TPR**)이라고도 하며, 다음과 같이 정의됩니다. \n",
    "$$ TPR = \\frac{TP}{FN + TP} $$\n",
    "\n",
    "거짓 양성 비율(False Positive Rate, **FPR**)은 다음과 같이 정의되며, TPR과 FPR은 서로 반비례 관계에 있습니다. \n",
    "$$ FPR = \\frac{FP}{TN + FP} $$\n",
    "\n",
    "ROC 곡선(Receiver Operation Characteristic Curve)은 FPR이 변할 때 TPR이 어떻게 변하는지를 나타내는 곡선입니다. FPR을 X축으로, TPR을 Y축으로 잡으면 FPR의 변화에 따른 TPR의 변화가 곡선으로 나타납니다. TPR과 FPR 모두 [0,1]의 범위이며, (0,0)에서 (1,1)을 잇는 곡선입니다. 이때 **ROC 곡선 아래 부분의 면적**을 **AUC(Area Under Curve)**라 하며, 일반적으로 1에 가까울수록 좋은 수치입니다. <br>\n",
    "\n",
    "사이킷런은 ROC AUC를 구해주는 **roc_auc_score()** API를 제공합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gV-t7Fi_k3JM",
    "outputId": "3774fba7-25b5-49e9-ff7d-7368fc9c16a6"
   },
   "outputs": [],
   "source": [
    "# Write your code!\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_score = roc_auc_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V4ZH0Zfik3JP"
   },
   "source": [
    "사이킷런에서 **roc_curve()** 함수를 이용하여 ROC를 계산할 수 있습니다. 첫 번째 파라미터로 실제값을, 두 번째 파라미터로 예측값을 입력하면 됩니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matplotlib를 불러옵니다.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 사이킷런의 roc_curve를 불러옵니다.\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DHncvH_1k3JQ",
    "outputId": "bc88dce0-0bea-4b44-9ee8-3d84eddd8d68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.  0.5 1. ] [0.   0.25 1.  ] [2 1 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1d335847588>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Write your code!\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "print(fpr, tpr, thresholds)\n",
    "\n",
    "plt.plot(fpr, tpr, label = 'ROC')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', label = 'Random')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DDQhMhM_k3JV"
   },
   "source": [
    "### Log Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SrsjEMY2k3JV"
   },
   "source": [
    "Log Loss는 이진 분류 모델을 측정하는 좋은 방법 중 하나이며, 로지스틱 회귀 및 신경망의 최적화 대상이기도 합니다. <br>\n",
    "\n",
    "Binary Log Loss의 공식은 다음과 같이 정의되며, p는 1을 예측할 확률을 나타냅니다. \n",
    "$$ log-loss = -\\frac{1}{n}\\sum_{i=1}^{n}\\log{p_{i}}+(1-y_{i})\\log{(1-p_{i})} $$ \n",
    "\n",
    "분류 모델의 결과가 예측 확률인 경우 Log Loss는 실제값과 얼마나 다른지에 따른 예측의 불확실성을 고려합니다. 이를 이용하여 모델의 성능을 향상시켜 볼 수 있습니다. 일반적으로 Log Loss를 최소화하면 분류 모델의 Accuracy가 높아집니다. <br>\n",
    "\n",
    "사이킷런은 Log Loss를 구하는 **log_loss()** 함수를 제공합니다. 첫 번째 파라미터로 실제값을, 두 번째 파라미터로 예측값을 입력하면 됩니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1ycs0Qblk3JW",
    "outputId": "13ba872e-81df-4335-d89c-d816ead289f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.99664685617295"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code!\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "log_loss(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T4vRX1lrk3JZ"
   },
   "source": [
    "## 2) 측정 공식 - 회귀 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "clqY3SkFk3Ja"
   },
   "source": [
    "이번에는 회귀 모델의 성능을 평가하는 방법에 대해 알아보겠습니다. <br>\n",
    "\n",
    "수치(Float) 값을 예측하는 모델은 정확도 등의 분류 모델 평가 기준으로 평가하는 것이 애매합니다. 분류 모델은 맞게 분류했는지/아닌지만 평가하면 되지만, 회귀 모델은 정확하게 예측하지 못했더라도, 정답과 비슷하게 맞추면 성능이 좋다고 평가해야 합니다. 따라서 회귀의 평가를 위한 지표는 실제값과 예측값의 차이를 기반으로 합니다. <br>\n",
    "\n",
    "이때 실제값과 예측값의 차이를 그냥 더하면 +와 -가 섞여서 오류가 상쇄됩니다. 이 때문에 오류의 절댓값 평균이나 제곱, 또는 제곱한 뒤 다시 루트를 씌운 평균값을 구합니다. 일반적으로 회귀의 성능을 평가하는 지표로는 **MAE**, **MSE**, **RMSE**, **R^2**, **MSLE**, **RMSLE** 등이 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qcYrsaYwk3Jb"
   },
   "source": [
    "우선, 회귀 모델에 대한 측정 공식을 알아보기 위한 예제 데이터셋을 랜덤으로 생성합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fgZ2MAcnk3Jb",
    "outputId": "6b013ade-d184-47c4-f803-1e022e0f77df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500,)\n",
      "(500,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>527</td>\n",
       "      <td>525.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>322</td>\n",
       "      <td>317.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>348</td>\n",
       "      <td>345.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>595</td>\n",
       "      <td>588.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>687</td>\n",
       "      <td>685.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>602</td>\n",
       "      <td>594.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>484</td>\n",
       "      <td>482.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>245</td>\n",
       "      <td>239.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>698</td>\n",
       "      <td>692.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>241</td>\n",
       "      <td>240.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    y_true  y_pred\n",
       "1      527   525.8\n",
       "2      322   317.2\n",
       "4      348   345.6\n",
       "6      595   588.7\n",
       "7      687   685.5\n",
       "10     602   594.8\n",
       "11     484   482.5\n",
       "13     245   239.4\n",
       "15     698   692.0\n",
       "22     241   240.5"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 코드를 실행할 때마다 랜덤으로 값이 만들어지기 때문에 결과를 고정하기 위해 seed를 고정합니다.\n",
    "np.random.seed = 123\n",
    "\n",
    "# np.random.randint()는 최솟값(low), 최대값(high), 개수(size)를 입력받습니다. \n",
    "# 최솟값과 최댓값 사이에서 지정한 개수만큼 랜덤하게 정수(Integer)를 추출합니다.\n",
    "y_true = np.random.randint(low=10, high=900, size=500)\n",
    "\n",
    "# np.random.random()는 개수(size)를 입력받습니다.\n",
    "# 구간 [0.0, 1.0)에서 지정한 개수만큼 랜덤하게 Floats를 추출합니다.\n",
    "y_pred = y_true + np.round(np.random.random(500), decimals=1) * np.random.randint(low=-10, high=10, size=500)\n",
    "\n",
    "# y_true와 y_pred의 shape를 확인합니다.\n",
    "# 500개가 잘 뽑혔다면 (500, 1) 또는 (500, )이 출력됩니다.\n",
    "print(y_true.shape)\n",
    "print(y_pred.shape)\n",
    "\n",
    "# y_true와 y_pred의 값을 확인합니다.\n",
    "y_df = pd.DataFrame(y_true, columns=['y_true'])\n",
    "y_df['y_pred'] = y_pred\n",
    "y_df[y_df['y_true'] > y_df['y_pred']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "497ipVCMk3Je"
   },
   "source": [
    "### MAE (Mean Absolute Error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PXCB5wylk3Je"
   },
   "source": [
    "MAE(Mean Absolute Error)는 실제값과 예측값의 차이를 **절댓값**으로 변환해 평균한 것입니다. \n",
    "$$ MAE = \\frac{1}{n}\\sum_{i=1}^{n}\\left|Y_{i}-\\hat{Y}_{i}\\right| $$\n",
    "\n",
    "MAE를 구하는 기능은 다음과 같이 구현할 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bTn4Ll-Ik3Jf",
    "outputId": "920b88ad-844d-4b77-ab19-58535cc25a92"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4894000000000007"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code!\n",
    "\n",
    "mae_1 = abs(y_pred - y_true).mean()\n",
    "mae_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UpLPNa0ik3Jh"
   },
   "source": [
    "사이킷런은 MAE를 계산하는 **mean_absolute_error()** 함수를 제공합니다. 첫 번째 파라미터로 실제값을, 두 번째 파라미터로 예측값을 입력하면 됩니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nHCS-1xEk3Ji",
    "outputId": "02ba2da1-0eaf-4a81-aeb0-8f6a2a2a2083"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4894000000000007"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code!\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "mae_2 = mean_absolute_error(y_true, y_pred)\n",
    "mae_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Thmo3TG-k3Jk"
   },
   "source": [
    "### MSE (Mean Squared Error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IBK5_U57k3Jl"
   },
   "source": [
    "MSE(Mean Squared Error)는 실제값과 예측값의 차이를 **제곱**해 평균한 것입니다. \n",
    "$$ MSE = \\frac{1}{n}\\sum_{i=1}^{n}(Y_{i}-\\hat{Y}_{i})^2 $$\n",
    "\n",
    "MSE를 구하는 기능은 다음과 같이 구현할 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e3wHCyclk3Jm",
    "outputId": "62654f4a-b68b-45d0-fedb-b2c6d25a3ac2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.10102"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code!\n",
    "\n",
    "mse_1 = ((y_true - y_pred) ** 2).mean()\n",
    "mse_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3sbakoVfk3Jo"
   },
   "source": [
    "사이킷런은 MSE를 계산하는 **mean_squared_error()** 함수를 제공합니다. 첫 번째 파라미터로 실제값을, 두 번째 파라미터로 예측값을 입력하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wdNx7SFvk3Jp",
    "outputId": "b52879a8-95e2-4554-d6cf-93c81312908b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.10102"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code!\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mse_2 = mean_squared_error(y_true, y_pred)\n",
    "mse_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NWuca5jTk3Jq"
   },
   "source": [
    "### RMSE (Root Mean Squared Error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IvlWPWgyk3Jr"
   },
   "source": [
    "RMSE(Root Mean Squared Error)는 MSE가 오류의 제곱을 구하므로 실제 오류 평균보다 더 커지는 특성이 있으므로 MSE에 **루트**를 씌운 것입니다.\n",
    "$$ RMSE = \\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}(Y_{i}-\\hat{Y}_{i})^2} $$\n",
    "\n",
    "사이킷런은 RMSE를 제공하지 않으므로 RMSE를 구하기 위해서는 MSE에 제곱근을 씌워서 계산하는 함수를 직접 만들어야 합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6vaF5Imzk3Js",
    "outputId": "f48d58fe-aea3-41c8-c88a-676890c19452"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.331819322832497"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code!\n",
    "\n",
    "rmse = np.sqrt(mse_1)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tIjDUHWJk3Jv"
   },
   "source": [
    "### MSLE (Mean Squared Logarithmic Error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FIwvQCX4k3Jv"
   },
   "source": [
    "MSLE(Mean Squared Logarithmic Error)는 실제값에 로그를 취한 값과 예측값에 로그를 취한 값의 차이를 **제곱**해 평균한 것입니다. \n",
    "\n",
    "$$ MSLE = \\frac{1}{n}\\sum_{i=1}^{n}(\\log{(p_{i}+1)}-\\log{(a_{i}+1)})^2 $$\n",
    "\n",
    "MSLE를 구하는 기능은 다음과 같이 구현할 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ay1exJ-Wk3Jw",
    "outputId": "8a33ef7f-28e5-443e-cf57-6a0801909877"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0014873935533056889"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code!\n",
    "# log1p = log( + 1) +1을 자동으로 해준 것\n",
    "msle_1 = ((np.log1p(y_pred) - np.log1p(y_true)) ** 2).mean()\n",
    "msle_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9nSNRcREk3Jz"
   },
   "source": [
    "사이킷런은 MSLE를 계산하는 **mean_squared_log_error()** 함수를 제공합니다. 첫 번째 파라미터로 실제값을, 두 번째 파라미터로 예측값을 입력하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ogGzbplzk3Jz",
    "outputId": "ac0b4bc0-a547-4216-edd4-602b4fd7a9d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0014873935533056889"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code!\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "msle_2 = mean_squared_log_error(y_true, y_pred)\n",
    "msle_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z0DnSjw_k3J1"
   },
   "source": [
    "### RMSLE (Root Mean Squared Logarithmic Error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d8Mvcdauk3J1"
   },
   "source": [
    "RMSLE(Root Mean Squared Logarithmic Error)는 MSLE가 오류의 제곱을 구하므로 실제 오류 평균보다 더 커지는 특성이 있으므로 MSLE에 **루트**를 씌운 것입니다.\n",
    "\n",
    "$$ RMSLE = \\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}(\\log{(p_{i}+1)}-\\log{(a_{i}+1)})^2} $$\n",
    "\n",
    "사이킷런은 RMSLE를 제공하지 않으므로 RMSLE를 구하기 위해서는 MSLE에 제곱근을 씌워서 계산하는 함수를 직접 만들어야 합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zOslpW0Sk3J2",
    "outputId": "1fd29b22-d634-4e77-e8c0-a5e35dd6bccf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03856674154379248"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code!\n",
    "\n",
    "rmsle = np.sqrt(msle_1)\n",
    "rmsle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C6ROGyHWk3J3"
   },
   "source": [
    "### R^2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yUzWdhTtk3J4"
   },
   "source": [
    "R^2는 분산 기반으로 예측 성능을 평가합니다. 실제값의 분산 대비 예측값의 분산 비율을 지표로 하며, 1에 가까울수록 예측 정확도가 높습니다. \n",
    "\n",
    "$$ R^2 = 1 - \\frac{SS_{res}}{SS_{tot}} = 1 - \\frac{\\sum_{i=1}^{n}(Y_{i}-\\hat{Y}_{i})^2}{\\sum_{i=1}^{n}(Y_{i}-\\bar{Y})^2} $$\n",
    "\n",
    "R^2를 구하는 기능은 다음과 같이 구현할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GEIziJzRk3J4",
    "outputId": "6d01c1c6-7804-46d8-da4a-87ee520e748b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9998347102155628"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code!\n",
    "\n",
    "ssres = sum((y_true - y_pred) ** 2)\n",
    "sstot = sum((y_true - y_true.mean()) ** 2)\n",
    "\n",
    "r2_1 = 1 - ssres / sstot\n",
    "r2_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1MD5lpXvk3J-"
   },
   "source": [
    "사이킷런은 R^2를 계산하는 **r2_score()** 함수를 제공합니다. 첫 번째 파라미터로 실제값을, 두 번째 파라미터로 예측값을 입력하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4ggOfg2Kk3J-",
    "outputId": "6e52aa96-0081-4a05-998b-49a20b97e9c8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9998347102155628"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code!\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2_2 = r2_score(y_true, y_pred)\n",
    "r2_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w0wUhYwzk3KC"
   },
   "source": [
    "### MAPE (Mean Absolute Percentage Error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eXCKB8JJk3KD"
   },
   "source": [
    "MAE(Mean Absolute Percentage Error)는 Scale Dependent Error의 단점을 커버하는 지표입니다. MAPE의 공식은 아래와 같습니다. \n",
    "$$ MAPE = \\frac{100}{n}\\sum_{i=1}^{n}\\left|\\frac{Y_{i}-\\hat{Y}_{i}}{Y_{i}}\\right| $$\n",
    "\n",
    "MAPE는 예측값과 실제값의 차이를 실제값으로 나눈 값의 절댓값을 평균한 후 100을 곱하여 백분율로 표현합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gXtbp59Qk3KD",
    "outputId": "43fbbc76-054f-489a-b79f-19c001c26149"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2406082999533108"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code!\n",
    "mape = abs((y_true - y_pred) / y_true).mean() * 100\n",
    "mape"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "07_Model_Evaluation-v2(수정중).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
